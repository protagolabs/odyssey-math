{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 16.00% (4/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 88.41% (61/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 76.60% (36/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 100.00% (5/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 71.43% (10/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 44.00% (11/25)\n",
      "  Calculus and Analysis - college math: 62.50% (15/24)\n",
      "  Probability - college math: 14.29% (3/21)\n",
      "  Statistics - college math: 64.71% (11/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 10.14% (15/148)\n",
      "  high school math: 84.78% (117/138)\n",
      "  college math: 49.50% (50/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 47.03% (182/387)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def calculate_accuracy(input_file):\n",
    "    results = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "    level_results = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "    overall = {'correct': 0, 'total': 0}  # Overall accuracy counter\n",
    "    \n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            problem_id = next(iter(data))  # Retrieve the problem identifier\n",
    "            problem_data = data[problem_id]\n",
    "            \n",
    "            label_level = f\"{problem_data['label']} - {problem_data['level']}\"\n",
    "            level = problem_data['level']\n",
    "            try:\n",
    "                # Try directly converting to int, assuming is_correct is simple integer or string\n",
    "                is_correct = int(problem_data['is_correct'])\n",
    "            except ValueError:\n",
    "                # Handle case where is_correct could be multiple values separated by newline or whitespace\n",
    "                if '\\n' in problem_data['is_correct'] or ' ' in problem_data['is_correct']:\n",
    "                    parts = re.split(r'\\s+', problem_data['is_correct'])\n",
    "                    for part in parts:\n",
    "                        try:\n",
    "                            is_correct = int(part)\n",
    "                            break\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                else:\n",
    "                    print(f\"Error parsing problem_id {problem_id} with data: {problem_data['is_correct']}\")\n",
    "                    match = re.search(r'Score:\\s*(-?\\d+)', problem_data['is_correct'])\n",
    "                    if match:\n",
    "                        is_correct = int(match.group(1))\n",
    "                    else:\n",
    "                        print(f\"No score found in problem_id {problem_id}. Assuming score of 0\")\n",
    "                        is_correct = 0  # Assuming score of 0 if no valid score can be parsed\n",
    "            \n",
    "            # Update counts for label-level combination\n",
    "            results[label_level]['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                results[label_level]['correct'] += 1\n",
    "            \n",
    "            # Update counts for level only\n",
    "            level_results[level]['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                level_results[level]['correct'] += 1\n",
    "\n",
    "            # Update overall accuracy counts\n",
    "            overall['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                overall['correct'] += 1\n",
    "\n",
    "    # Print accuracy for each label-level category\n",
    "    print(\"Accuracy by Label and Level:\")\n",
    "    for category, counts in results.items():\n",
    "        accuracy = counts['correct'] / counts['total'] * 100\n",
    "        print(f\"  {category}: {accuracy:.2f}% ({counts['correct']}/{counts['total']})\")\n",
    "\n",
    "    # Print overall accuracy by level\n",
    "    print(\"\\nOverall Accuracy by Level:\")\n",
    "    for level, counts in level_results.items():\n",
    "        accuracy = counts['correct'] / counts['total'] * 100\n",
    "        print(f\"  {level}: {accuracy:.2f}% ({counts['correct']}/{counts['total']})\")\n",
    "\n",
    "    # Print overall accuracy for the entire dataset\n",
    "    total_accuracy = overall['correct'] / overall['total'] * 100\n",
    "    print(f\"\\nOverall Accuracy for the Entire Dataset: {total_accuracy:.2f}% ({overall['correct']}/{overall['total']})\")\n",
    "\n",
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-turbo-2024-04-09-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 14.63% (12/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 71.01% (49/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 74.47% (35/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 42.86% (6/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 40.00% (10/25)\n",
      "  Calculus and Analysis - college math: 58.33% (14/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 58.82% (10/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 11.49% (17/148)\n",
      "  high school math: 74.64% (103/138)\n",
      "  college math: 41.58% (42/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 41.86% (162/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-0125-preview-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 7.32% (6/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 8.00% (2/25)\n",
      "  Combinatorics - high school competition: 2.70% (1/37)\n",
      "  Algebra - high school math: 47.83% (33/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 65.96% (31/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 100.00% (5/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 50.00% (7/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 36.00% (9/25)\n",
      "  Calculus and Analysis - college math: 41.67% (10/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 52.94% (9/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 6.08% (9/148)\n",
      "  high school math: 60.14% (83/138)\n",
      "  college math: 36.63% (37/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 33.33% (129/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-1106-preview-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 4.88% (4/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 8.11% (3/37)\n",
      "  Algebra - high school math: 73.91% (51/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 72.34% (34/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 60.00% (3/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 42.86% (6/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 44.00% (11/25)\n",
      "  Calculus and Analysis - college math: 45.83% (11/24)\n",
      "  Probability - college math: 0.00% (0/21)\n",
      "  Statistics - college math: 29.41% (5/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 5.41% (8/148)\n",
      "  high school math: 74.64% (103/138)\n",
      "  college math: 32.67% (33/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 37.21% (144/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-0613-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 2.44% (2/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 0.00% (0/37)\n",
      "  Algebra - high school math: 39.13% (27/69)\n",
      "  Geometry - high school math: 71.43% (10/14)\n",
      "  PreCalculus - high school math: 34.04% (16/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 40.00% (2/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 28.57% (4/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 16.00% (4/25)\n",
      "  Calculus and Analysis - college math: 16.67% (4/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 11.76% (2/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 2.03% (3/148)\n",
      "  high school math: 41.30% (57/138)\n",
      "  college math: 15.84% (16/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 19.64% (76/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-3.5-turbo-0125-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 25.00% (1/4)\n",
      "  Geometry - high school competition: 8.00% (2/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 44.93% (31/69)\n",
      "  Geometry - high school math: 71.43% (10/14)\n",
      "  PreCalculus - high school math: 55.32% (26/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 50.00% (7/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 24.00% (6/25)\n",
      "  Calculus and Analysis - college math: 20.83% (5/24)\n",
      "  Probability - college math: 0.00% (0/21)\n",
      "  Statistics - college math: 23.53% (4/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 9.46% (14/148)\n",
      "  high school math: 52.17% (72/138)\n",
      "  college math: 21.78% (22/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 27.91% (108/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-llama3-70b-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 4.88% (4/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 20.00% (5/25)\n",
      "  Combinatorics - high school competition: 8.11% (3/37)\n",
      "  Algebra - high school math: 39.13% (27/69)\n",
      "  Geometry - high school math: 57.14% (8/14)\n",
      "  PreCalculus - high school math: 40.43% (19/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 60.00% (3/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 28.57% (4/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 28.00% (7/25)\n",
      "  Calculus and Analysis - college math: 12.50% (3/24)\n",
      "  Probability - college math: 4.76% (1/21)\n",
      "  Statistics - college math: 35.29% (6/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 8.11% (12/148)\n",
      "  high school math: 42.75% (59/138)\n",
      "  college math: 20.79% (21/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 23.77% (92/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-dbrx-instruct-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
