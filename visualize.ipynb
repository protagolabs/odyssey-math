{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 16.00% (4/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 88.41% (61/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 76.60% (36/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 100.00% (5/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 71.43% (10/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 44.00% (11/25)\n",
      "  Calculus and Analysis - college math: 62.50% (15/24)\n",
      "  Probability - college math: 14.29% (3/21)\n",
      "  Statistics - college math: 64.71% (11/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 10.14% (15/148)\n",
      "  high school math: 84.78% (117/138)\n",
      "  college math: 49.50% (50/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 47.03% (182/387)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def calculate_accuracy(input_file):\n",
    "    results = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "    level_results = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "    overall = {'correct': 0, 'total': 0}  # Overall accuracy counter\n",
    "    \n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            problem_id = next(iter(data))  # Retrieve the problem identifier\n",
    "            problem_data = data[problem_id]\n",
    "            \n",
    "            label_level = f\"{problem_data['label']} - {problem_data['level']}\"\n",
    "            level = problem_data['level']\n",
    "            try:\n",
    "                # Try directly converting to int, assuming is_correct is simple integer or string\n",
    "                is_correct = int(problem_data['is_correct'])\n",
    "            except ValueError:\n",
    "                # Handle case where is_correct could be multiple values separated by newline or whitespace\n",
    "                if '\\n' in problem_data['is_correct'] or ' ' in problem_data['is_correct']:\n",
    "                    parts = re.split(r'\\s+', problem_data['is_correct'])\n",
    "                    for part in parts:\n",
    "                        try:\n",
    "                            is_correct = int(part)\n",
    "                            break\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                else:\n",
    "                    print(f\"Error parsing problem_id {problem_id} with data: {problem_data['is_correct']}\")\n",
    "                    match = re.search(r'Score:\\s*(-?\\d+)', problem_data['is_correct'])\n",
    "                    if match:\n",
    "                        is_correct = int(match.group(1))\n",
    "                    else:\n",
    "                        print(f\"No score found in problem_id {problem_id}. Assuming score of 0\")\n",
    "                        is_correct = 0  # Assuming score of 0 if no valid score can be parsed\n",
    "            \n",
    "            # Update counts for label-level combination\n",
    "            results[label_level]['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                results[label_level]['correct'] += 1\n",
    "            \n",
    "            # Update counts for level only\n",
    "            level_results[level]['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                level_results[level]['correct'] += 1\n",
    "\n",
    "            # Update overall accuracy counts\n",
    "            overall['total'] += 1\n",
    "            if is_correct == 1:\n",
    "                overall['correct'] += 1\n",
    "\n",
    "    # Print accuracy for each label-level category\n",
    "    print(\"Accuracy by Label and Level:\")\n",
    "    for category, counts in results.items():\n",
    "        accuracy = counts['correct'] / counts['total'] * 100\n",
    "        print(f\"  {category}: {accuracy:.2f}% ({counts['correct']}/{counts['total']})\")\n",
    "\n",
    "    # Print overall accuracy by level\n",
    "    print(\"\\nOverall Accuracy by Level:\")\n",
    "    for level, counts in level_results.items():\n",
    "        accuracy = counts['correct'] / counts['total'] * 100\n",
    "        print(f\"  {level}: {accuracy:.2f}% ({counts['correct']}/{counts['total']})\")\n",
    "\n",
    "    # Print overall accuracy for the entire dataset\n",
    "    total_accuracy = overall['correct'] / overall['total'] * 100\n",
    "    print(f\"\\nOverall Accuracy for the Entire Dataset: {total_accuracy:.2f}% ({overall['correct']}/{overall['total']})\")\n",
    "\n",
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-turbo-2024-04-09-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 51.22% (42/82)\n",
      "  NumberTheory - high school competition: 75.00% (3/4)\n",
      "  Geometry - high school competition: 56.00% (14/25)\n",
      "  Combinatorics - high school competition: 21.62% (8/37)\n",
      "  Algebra - high school math: 81.16% (56/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 74.47% (35/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 71.43% (10/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 92.00% (23/25)\n",
      "  Calculus and Analysis - college math: 79.17% (19/24)\n",
      "  Probability - college math: 52.38% (11/21)\n",
      "  Statistics - college math: 70.59% (12/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 45.27% (67/148)\n",
      "  high school math: 79.71% (110/138)\n",
      "  college math: 74.26% (75/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 65.12% (252/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-o1-preview-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 9.76% (8/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 78.26% (54/69)\n",
      "  Geometry - high school math: 85.71% (12/14)\n",
      "  PreCalculus - high school math: 68.09% (32/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 20.00% (1/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 64.29% (9/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 20.00% (5/25)\n",
      "  Calculus and Analysis - college math: 33.33% (8/24)\n",
      "  Probability - college math: 0.00% (0/21)\n",
      "  Statistics - college math: 17.65% (3/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 8.78% (13/148)\n",
      "  high school math: 73.19% (101/138)\n",
      "  college math: 24.75% (25/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 35.92% (139/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-0613-solution-clean-last.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 7.32% (6/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 12.00% (3/25)\n",
      "  Combinatorics - high school competition: 2.70% (1/37)\n",
      "  Algebra - high school math: 65.22% (45/69)\n",
      "  Geometry - high school math: 78.57% (11/14)\n",
      "  PreCalculus - high school math: 63.83% (30/47)\n",
      "  Trigonometry - high school math: 100.00% (2/2)\n",
      "  Calculus - high school math: 40.00% (2/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 78.57% (11/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 24.00% (6/25)\n",
      "  Calculus and Analysis - college math: 33.33% (8/24)\n",
      "  Probability - college math: 14.29% (3/21)\n",
      "  Statistics - college math: 47.06% (8/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 6.76% (10/148)\n",
      "  high school math: 65.94% (91/138)\n",
      "  college math: 35.64% (36/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 35.40% (137/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-output.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 25.00% (1/4)\n",
      "  Geometry - high school competition: 16.00% (4/25)\n",
      "  Combinatorics - high school competition: 8.11% (3/37)\n",
      "  Algebra - high school math: 44.93% (31/69)\n",
      "  Geometry - high school math: 78.57% (11/14)\n",
      "  PreCalculus - high school math: 53.19% (25/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 57.14% (8/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 28.00% (7/25)\n",
      "  Calculus and Analysis - college math: 20.83% (5/24)\n",
      "  Probability - college math: 4.76% (1/21)\n",
      "  Statistics - college math: 23.53% (4/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 10.14% (15/148)\n",
      "  high school math: 52.17% (72/138)\n",
      "  college math: 24.75% (25/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 28.94% (112/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-output-original.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 8.00% (2/25)\n",
      "  Combinatorics - high school competition: 5.41% (2/37)\n",
      "  Algebra - high school math: 72.46% (50/69)\n",
      "  Geometry - high school math: 85.71% (12/14)\n",
      "  PreCalculus - high school math: 63.83% (30/47)\n",
      "  Trigonometry - high school math: 100.00% (2/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 42.86% (6/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 36.00% (9/25)\n",
      "  Calculus and Analysis - college math: 41.67% (10/24)\n",
      "  Probability - college math: 14.29% (3/21)\n",
      "  Statistics - college math: 17.65% (3/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 7.43% (11/148)\n",
      "  high school math: 71.74% (99/138)\n",
      "  college math: 30.69% (31/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 36.43% (141/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-output-last.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 14.63% (12/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 71.01% (49/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 74.47% (35/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 42.86% (6/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 40.00% (10/25)\n",
      "  Calculus and Analysis - college math: 58.33% (14/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 58.82% (10/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 11.49% (17/148)\n",
      "  high school math: 74.64% (103/138)\n",
      "  college math: 41.58% (42/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 41.86% (162/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-0125-preview-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 7.32% (6/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 8.00% (2/25)\n",
      "  Combinatorics - high school competition: 2.70% (1/37)\n",
      "  Algebra - high school math: 47.83% (33/69)\n",
      "  Geometry - high school math: 92.86% (13/14)\n",
      "  PreCalculus - high school math: 65.96% (31/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 100.00% (5/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 50.00% (7/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 36.00% (9/25)\n",
      "  Calculus and Analysis - college math: 41.67% (10/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 52.94% (9/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 6.08% (9/148)\n",
      "  high school math: 60.14% (83/138)\n",
      "  college math: 36.63% (37/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 33.33% (129/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-1106-preview-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 4.88% (4/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 8.11% (3/37)\n",
      "  Algebra - high school math: 78.26% (54/69)\n",
      "  Geometry - high school math: 85.71% (12/14)\n",
      "  PreCalculus - high school math: 74.47% (35/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 60.00% (3/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 35.71% (5/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 32.00% (8/25)\n",
      "  Calculus and Analysis - college math: 37.50% (9/24)\n",
      "  Probability - college math: 0.00% (0/21)\n",
      "  Statistics - college math: 35.29% (6/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 5.41% (8/148)\n",
      "  high school math: 76.09% (105/138)\n",
      "  college math: 27.72% (28/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 36.43% (141/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-4-0613-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 2.44% (2/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 4.00% (1/25)\n",
      "  Combinatorics - high school competition: 0.00% (0/37)\n",
      "  Algebra - high school math: 39.13% (27/69)\n",
      "  Geometry - high school math: 71.43% (10/14)\n",
      "  PreCalculus - high school math: 34.04% (16/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 40.00% (2/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 28.57% (4/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 16.00% (4/25)\n",
      "  Calculus and Analysis - college math: 16.67% (4/24)\n",
      "  Probability - college math: 9.52% (2/21)\n",
      "  Statistics - college math: 11.76% (2/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 2.03% (3/148)\n",
      "  high school math: 41.30% (57/138)\n",
      "  college math: 15.84% (16/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 19.64% (76/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-gpt-3.5-turbo-0125-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 8.54% (7/82)\n",
      "  NumberTheory - high school competition: 25.00% (1/4)\n",
      "  Geometry - high school competition: 8.00% (2/25)\n",
      "  Combinatorics - high school competition: 10.81% (4/37)\n",
      "  Algebra - high school math: 44.93% (31/69)\n",
      "  Geometry - high school math: 71.43% (10/14)\n",
      "  PreCalculus - high school math: 55.32% (26/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 80.00% (4/5)\n",
      "  Series - high school math: 0.00% (0/1)\n",
      "  Differential Equations - college math: 50.00% (7/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 24.00% (6/25)\n",
      "  Calculus and Analysis - college math: 20.83% (5/24)\n",
      "  Probability - college math: 0.00% (0/21)\n",
      "  Statistics - college math: 23.53% (4/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 9.46% (14/148)\n",
      "  high school math: 52.17% (72/138)\n",
      "  college math: 21.78% (22/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 27.91% (108/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-llama3-70b-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Label and Level:\n",
      "  Algebra - high school competition: 4.88% (4/82)\n",
      "  NumberTheory - high school competition: 0.00% (0/4)\n",
      "  Geometry - high school competition: 20.00% (5/25)\n",
      "  Combinatorics - high school competition: 8.11% (3/37)\n",
      "  Algebra - high school math: 39.13% (27/69)\n",
      "  Geometry - high school math: 57.14% (8/14)\n",
      "  PreCalculus - high school math: 40.43% (19/47)\n",
      "  Trigonometry - high school math: 50.00% (1/2)\n",
      "  Calculus - high school math: 60.00% (3/5)\n",
      "  Series - high school math: 100.00% (1/1)\n",
      "  Differential Equations - college math: 28.57% (4/14)\n",
      "  Linear Algebra and Abstract Algebra - college math: 28.00% (7/25)\n",
      "  Calculus and Analysis - college math: 12.50% (3/24)\n",
      "  Probability - college math: 4.76% (1/21)\n",
      "  Statistics - college math: 35.29% (6/17)\n",
      "\n",
      "Overall Accuracy by Level:\n",
      "  high school competition: 8.11% (12/148)\n",
      "  high school math: 42.75% (59/138)\n",
      "  college math: 20.79% (21/101)\n",
      "\n",
      "Overall Accuracy for the Entire Dataset: 23.77% (92/387)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSONL file\n",
    "input_file_path = 'jsonl/eval/result-dbrx-instruct-solution-clean.jsonl'\n",
    "\n",
    "# Call the function\n",
    "calculate_accuracy(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Category:\n",
      "Category\n",
      "Multiple Choice    0.460938\n",
      "Open Question      0.098361\n",
      "True-False         0.600000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_236382/1108499678.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  accuracy = merged_df.groupby('Category').apply(lambda x: x['is_correct'].astype(int).mean())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_accuracy_by_category(jsonl_file_path, txt_file_path):\n",
    "    # Load the JSONL file into a list of dictionaries\n",
    "    def load_jsonl(file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line.strip()))\n",
    "        return data\n",
    "\n",
    "    # Load the TXT file into a DataFrame\n",
    "    def load_txt(file_path):\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None, names=['Problem_ID', 'Level', 'Category'])\n",
    "        return df\n",
    "\n",
    "    # Calculate accuracy based on categories\n",
    "    def calculate_accuracy(jsonl_data, txt_data):\n",
    "        # Convert jsonl_data to a DataFrame\n",
    "        jsonl_df = pd.DataFrame([{'Problem_ID': k, **v} for d in jsonl_data for k, v in d.items()])\n",
    "        jsonl_df['Problem_ID'] = jsonl_df['Problem_ID'].str.replace('Problem_', '').astype(int)\n",
    "\n",
    "        # Merge the two DataFrames on Problem_ID\n",
    "        merged_df = pd.merge(jsonl_df, txt_data, on='Problem_ID')\n",
    "\n",
    "        # Calculate accuracy for each category\n",
    "        accuracy = merged_df.groupby('Category').apply(lambda x: x['is_correct'].astype(int).mean())\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # Load the data\n",
    "    jsonl_data = load_jsonl(jsonl_file_path)\n",
    "    txt_data = load_txt(txt_file_path)\n",
    "\n",
    "    # Calculate and return accuracy\n",
    "    return calculate_accuracy(jsonl_data, txt_data)\n",
    "\n",
    "# Example usage:\n",
    "jsonl_file_path = '/root/Xiangpeng/odyssey-math/jsonl/eval/result-dbrx-instruct-solution-clean.jsonl'\n",
    "txt_file_path = 'jsonl/processed.txt'\n",
    "\n",
    "accuracy_results = calculate_accuracy_by_category(jsonl_file_path, txt_file_path)\n",
    "\n",
    "print(\"Accuracy by Category:\")\n",
    "print(accuracy_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
