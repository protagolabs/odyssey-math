{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong:Problem_10\n",
      "something went wrong:Problem_18\n",
      "something went wrong:Problem_21\n",
      "something went wrong:Problem_24\n",
      "something went wrong:Problem_32\n",
      "something went wrong:Problem_36\n",
      "something went wrong:Problem_39\n",
      "something went wrong:Problem_40\n",
      "something went wrong:Problem_46\n",
      "something went wrong:Problem_50\n",
      "something went wrong:Problem_64\n",
      "something went wrong:Problem_67\n",
      "something went wrong:Problem_70\n",
      "something went wrong:Problem_76\n",
      "something went wrong:Problem_95\n",
      "something went wrong:Problem_147\n",
      "something went wrong:Problem_294\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# read jsonl file from disk\n",
    "with open('deepseek-v3-Instruct-solution.jsonl', 'r') as f:\n",
    "    jsonl_lines = f.readlines()\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_answer(data, problem_id):\n",
    "    # Step 1: Find the location of the \"answer\" keyword\n",
    "    answer_start = data.find('answer')\n",
    "    if answer_start == -1:\n",
    "        print(f'something went wrong:{problem_id}')\n",
    "        return None  # If \"answer\" is not found, return None\n",
    "\n",
    "    # Step 2: Find the start of the value after \"answer\"\n",
    "    answer_start = data.find(':', answer_start)  # Find the colon after \"answer\"\n",
    "    if answer_start == -1:\n",
    "        print(f'something went wrong:{problem_id}')\n",
    "        return None  # If the colon is not found, return None\n",
    "\n",
    "    # Step 3: Find the first occurrence of \"\\ndata\" after the colon\n",
    "    data_end = data.find(\"}\", answer_start)\n",
    "    if data_end == -1:\n",
    "        print(f'something went wrong:{problem_id}')\n",
    "        return None  \n",
    "\n",
    "    # Step 4: Extract the value between the colon and the first \"\\ndata\"\n",
    "    answer_value = data[answer_start + 1:data_end].strip().strip('\"')\n",
    "\n",
    "    return answer_value\n",
    "\n",
    "# Function to extract Problem ID and Answer\n",
    "def extract_problem_and_answer(jsonl_lines):\n",
    "    extracted_data = []\n",
    "    for line in jsonl_lines:\n",
    "        # Assuming the first key is always the problem id\n",
    "        data = json.loads(line)\n",
    "        problem_id = list(data.keys())[0]  # Get the first key as problem ID\n",
    "        problem_data = data[problem_id]  # Get the associated data as a string\n",
    "\n",
    "        answer = extract_answer(problem_data, problem_id)\n",
    "\n",
    "        # Construct the JSONL format output\n",
    "        extracted_data.append({problem_id: {\"answer\": str(answer)}})\n",
    "    \n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Extract data from the JSONL lines\n",
    "result = extract_problem_and_answer(jsonl_lines)\n",
    "\n",
    "# Output the extracted problem IDs and answers in JSONL format\n",
    "with open('clean/deepseek-v3-Instruct-solution-clean.jsonl', 'w') as f:\n",
    "    for item in result:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read jsonl file from disk\n",
    "with open('llama3-70b-solution-last.jsonl', 'r') as f:\n",
    "    jsonl_lines = f.readlines()\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_answer(data):\n",
    "    # Step 1: Find the location of the \"answer\" keyword\n",
    "    answer_start = data.find('\"answer')\n",
    "    if answer_start == -1:\n",
    "        return None  # If \"answer\" is not found, return None\n",
    "\n",
    "    # Step 2: Find the start of the value after \"answer\"\n",
    "    answer_start = data.find(':', answer_start)  # Find the colon after \"answer\"\n",
    "    if answer_start == -1:\n",
    "        return None  # If the colon is not found, return None\n",
    "\n",
    "    # Step 3: Find the first occurrence of \"\\ndata\" after the colon\n",
    "    data_end = data.find(\"\\ndata\", answer_start)\n",
    "    if data_end == -1:\n",
    "        return None  # If \"\\ndata\" is not found, return None\n",
    "\n",
    "    # Step 4: Extract the value between the colon and the first \"\\ndata\"\n",
    "    answer_value = data[answer_start + 1:data_end].strip().strip('\"')\n",
    "\n",
    "    return answer_value\n",
    "\n",
    "# Function to extract Problem ID and Answer\n",
    "def extract_problem_and_answer(jsonl_lines):\n",
    "    extracted_data = []\n",
    "    for line in jsonl_lines:\n",
    "        # Try to load the JSON data from the line\n",
    "        try:\n",
    "            # Assuming the first key is always the problem id\n",
    "            data = json.loads(line)\n",
    "            problem_id = list(data.keys())[0]  # Get the first key as problem ID\n",
    "            problem_data = data[problem_id]  # Get the associated data as a string\n",
    "\n",
    "            # Find and extract the JSON object in the 'data' field\n",
    "            start_index = problem_data.find('{')\n",
    "            end_index = problem_data.rfind('}') + 1\n",
    "\n",
    "            answer = extract_answer(problem_data[start_index:end_index])\n",
    "\n",
    "            # Construct the JSONL format output\n",
    "            extracted_data.append({problem_id: {\"answer\": str(answer)}})\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Extract data from the JSONL lines\n",
    "result = extract_problem_and_answer(jsonl_lines)\n",
    "\n",
    "# Output the extracted problem IDs and answers in JSONL format\n",
    "with open('clean/output-last.jsonl', 'w') as f:\n",
    "    for item in result:\n",
    "        f.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong:```json\n",
      "{\n",
      "    \"a\": -3,\n",
      "    \"b\": 4\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# read jsonl file from disk\n",
    "with open('gpt-4-o1-preview-solution.jsonl', 'r') as f:\n",
    "    jsonl_lines = f.readlines()\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_answer(data):\n",
    "    # Step 1: Find the location of the \"answer\" keyword\n",
    "    answer_start = data.find('answer')\n",
    "    if answer_start == -1:\n",
    "        print(f'something went wrong:{data}')\n",
    "        return None  # If \"answer\" is not found, return None\n",
    "\n",
    "    # Step 2: Find the start of the value after \"answer\"\n",
    "    answer_start = data.find(':', answer_start)  # Find the colon after \"answer\"\n",
    "    if answer_start == -1:\n",
    "        print(f'something went wrong:{data}')\n",
    "        return None  # If the colon is not found, return None\n",
    "\n",
    "    # Step 3: Find the first occurrence of \"\\ndata\" after the colon\n",
    "    data_end = data.find(\"}\", answer_start)\n",
    "    if data_end == -1:\n",
    "        print(f'something went wrong:{data}')\n",
    "        return None  \n",
    "\n",
    "    # Step 4: Extract the value between the colon and the first \"\\ndata\"\n",
    "    answer_value = data[answer_start + 1:data_end].strip().strip('\"')\n",
    "\n",
    "    return answer_value\n",
    "\n",
    "# Function to extract Problem ID and Answer\n",
    "def extract_problem_and_answer(jsonl_lines):\n",
    "    extracted_data = []\n",
    "    for line in jsonl_lines:\n",
    "        # Assuming the first key is always the problem id\n",
    "        data = json.loads(line)\n",
    "        problem_id = list(data.keys())[0]  # Get the first key as problem ID\n",
    "        problem_data = data[problem_id]  # Get the associated data as a string\n",
    "\n",
    "        answer = extract_answer(problem_data)\n",
    "\n",
    "        # Construct the JSONL format output\n",
    "        extracted_data.append({problem_id: {\"answer\": str(answer)}})\n",
    "    \n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Extract data from the JSONL lines\n",
    "result = extract_problem_and_answer(jsonl_lines)\n",
    "\n",
    "# Output the extracted problem IDs and answers in JSONL format\n",
    "with open('clean/gpt-4-o1-preview-solution-clean.jsonl', 'w') as f:\n",
    "    for item in result:\n",
    "        f.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem_5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '/root/Xiangpeng/odyssey-math/jsonl/gpt-4-turbo-2024-04-09-second.jsonl'\n",
    "output_file = 'clean/gpt-4-turbo-2024-04-09-second-clean-new.jsonl'\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract only the answer and restructure the JSON\n",
    "        for key, value in data.items():\n",
    "            try:\n",
    "                # Fix escape sequences in the nested JSON string\n",
    "                fixed_value = escape_backslashes(value)\n",
    "                value = json.loads(fixed_value)\n",
    "                cleaned_data = {key: {\"answer\": value[\"answer\"]}}\n",
    "                # Write the cleaned JSON back to the output file\n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "            except:\n",
    "                cleaned_data = {key: {\"answer\": None}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "                print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to properly escape backslashes in JSON strings\n",
    "def escape_backslashes(text):\n",
    "    # Replace single backslashes with double backslashes\n",
    "    return text.replace(\"\\\\\", \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem_7\n",
      "Problem_24\n",
      "Problem_71\n",
      "Problem_85\n",
      "Problem_245\n",
      "Problem_261\n",
      "Problem_354\n",
      "Problem_384\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '/root/Xiangpeng/odyssey-math/jsonl/gpt-4-0125-preview-solution-new.jsonl'\n",
    "output_file = 'clean/gpt-4-0125-preview-solution-clean-new.jsonl'\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract only the answer and restructure the JSON\n",
    "        for key, value in data.items():\n",
    "            try:\n",
    "                # Fix escape sequences in the nested JSON string\n",
    "                fixed_value = escape_backslashes(value)\n",
    "                value = json.loads(fixed_value)\n",
    "                cleaned_data = {key: {\"answer\": value[\"answer\"]}}\n",
    "                # Write the cleaned JSON back to the output file\n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "            except:\n",
    "                cleaned_data = {key: {\"answer\": None}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "                print(key)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No answer field found in the Problem_10\n",
      "No answer field found in the Problem_16\n",
      "No answer field found in the Problem_20\n",
      "No answer field found in the Problem_38\n",
      "No answer field found in the Problem_57\n",
      "No answer field found in the Problem_119\n",
      "No answer field found in the Problem_139\n",
      "No answer field found in the Problem_146\n",
      "No answer field found in the Problem_293\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '/root/Xiangpeng/odyssey-math/jsonl/gpt-4-1106-preview.jsonl'\n",
    "output_file = 'clean/gpt-4-1106-preview-solution-clean-new.jsonl'\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract only the answer and restructure the JSON\n",
    "        for key, value in data.items():\n",
    "            \n",
    "            # Find the start position of the last \"answer\":\n",
    "            start_pos = value.rfind('\"answer\":')\n",
    "            if start_pos != -1:\n",
    "                end_pos = value.find('}', start_pos)\n",
    "                captured_answer = value[start_pos:end_pos+1]\n",
    "                \n",
    "                cleaned_data = {key: {\"answer\": captured_answer.strip()}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "            else:\n",
    "                print(f\"No answer field found in the {key}\")\n",
    "                cleaned_data = {key: {\"answer\": None}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No answer field found in the Problem_3\n",
      "No answer field found in the Problem_8\n",
      "No answer field found in the Problem_9\n",
      "No answer field found in the Problem_10\n",
      "No answer field found in the Problem_12\n",
      "No answer field found in the Problem_13\n",
      "No answer field found in the Problem_14\n",
      "No answer field found in the Problem_15\n",
      "No answer field found in the Problem_17\n",
      "No answer field found in the Problem_19\n",
      "No answer field found in the Problem_20\n",
      "No answer field found in the Problem_24\n",
      "No answer field found in the Problem_25\n",
      "No answer field found in the Problem_27\n",
      "No answer field found in the Problem_28\n",
      "No answer field found in the Problem_32\n",
      "No answer field found in the Problem_34\n",
      "No answer field found in the Problem_37\n",
      "No answer field found in the Problem_41\n",
      "No answer field found in the Problem_42\n",
      "No answer field found in the Problem_44\n",
      "No answer field found in the Problem_46\n",
      "No answer field found in the Problem_47\n",
      "No answer field found in the Problem_50\n",
      "No answer field found in the Problem_51\n",
      "No answer field found in the Problem_53\n",
      "No answer field found in the Problem_54\n",
      "No answer field found in the Problem_55\n",
      "No answer field found in the Problem_61\n",
      "No answer field found in the Problem_63\n",
      "No answer field found in the Problem_64\n",
      "No answer field found in the Problem_67\n",
      "No answer field found in the Problem_68\n",
      "No answer field found in the Problem_70\n",
      "No answer field found in the Problem_73\n",
      "No answer field found in the Problem_76\n",
      "No answer field found in the Problem_79\n",
      "No answer field found in the Problem_84\n",
      "No answer field found in the Problem_85\n",
      "No answer field found in the Problem_87\n",
      "No answer field found in the Problem_88\n",
      "No answer field found in the Problem_90\n",
      "No answer field found in the Problem_91\n",
      "No answer field found in the Problem_92\n",
      "No answer field found in the Problem_96\n",
      "No answer field found in the Problem_97\n",
      "No answer field found in the Problem_98\n",
      "No answer field found in the Problem_100\n",
      "No answer field found in the Problem_101\n",
      "No answer field found in the Problem_102\n",
      "No answer field found in the Problem_108\n",
      "No answer field found in the Problem_110\n",
      "No answer field found in the Problem_111\n",
      "No answer field found in the Problem_112\n",
      "No answer field found in the Problem_114\n",
      "No answer field found in the Problem_117\n",
      "No answer field found in the Problem_120\n",
      "No answer field found in the Problem_122\n",
      "No answer field found in the Problem_126\n",
      "No answer field found in the Problem_127\n",
      "No answer field found in the Problem_129\n",
      "No answer field found in the Problem_134\n",
      "No answer field found in the Problem_137\n",
      "No answer field found in the Problem_140\n",
      "No answer field found in the Problem_141\n",
      "No answer field found in the Problem_142\n",
      "No answer field found in the Problem_143\n",
      "No answer field found in the Problem_144\n",
      "No answer field found in the Problem_146\n",
      "No answer field found in the Problem_147\n",
      "No answer field found in the Problem_148\n",
      "No answer field found in the Problem_169\n",
      "No answer field found in the Problem_180\n",
      "No answer field found in the Problem_188\n",
      "No answer field found in the Problem_220\n",
      "No answer field found in the Problem_264\n",
      "No answer field found in the Problem_287\n",
      "No answer field found in the Problem_299\n",
      "No answer field found in the Problem_300\n",
      "No answer field found in the Problem_313\n",
      "No answer field found in the Problem_316\n",
      "No answer field found in the Problem_319\n",
      "No answer field found in the Problem_321\n",
      "No answer field found in the Problem_327\n",
      "No answer field found in the Problem_329\n",
      "No answer field found in the Problem_331\n",
      "No answer field found in the Problem_332\n",
      "No answer field found in the Problem_334\n",
      "No answer field found in the Problem_339\n",
      "No answer field found in the Problem_342\n",
      "No answer field found in the Problem_344\n",
      "No answer field found in the Problem_345\n",
      "No answer field found in the Problem_346\n",
      "No answer field found in the Problem_348\n",
      "No answer field found in the Problem_350\n",
      "No answer field found in the Problem_352\n",
      "No answer field found in the Problem_361\n",
      "No answer field found in the Problem_368\n",
      "No answer field found in the Problem_377\n",
      "No answer field found in the Problem_380\n",
      "No answer field found in the Problem_385\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '/root/Xiangpeng/odyssey-math/jsonl/gpt-3.5-turbo-0125.jsonl'\n",
    "output_file = 'clean/gpt-3.5-turbo-0125-solution-clean-new.jsonl'\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract only the answer and restructure the JSON\n",
    "        for key, value in data.items():\n",
    "            \n",
    "            # Find the start position of the last \"answer\":\n",
    "            start_pos = value.rfind('\"answer\":')\n",
    "            if start_pos != -1:\n",
    "                end_pos = value.find('}', start_pos)\n",
    "                captured_answer = value[start_pos:end_pos+1]\n",
    "                \n",
    "                cleaned_data = {key: {\"answer\": captured_answer.strip()}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "            else:\n",
    "                print(f\"No answer field found in the {key}\")\n",
    "                cleaned_data = {key: {\"answer\": None}}    \n",
    "                outfile.write(json.dumps(cleaned_data) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
